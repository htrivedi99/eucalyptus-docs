# Quickstart

<br/>

Lets get you up and running!
___

### Install the python package

```python
pip install eucalyptus
```

### Import package and initialize sdk
```python
import eucalyptus

eucalyptus.initialize(api_token="<API_TOKEN_STRING>")
```


:::{admonition} Note
:class: note

API tokens can be generated by going to the My account tab

:::

```{image} ../images/api-key-screenshot.png
:width: 300px
```

### Creating a New Model
```python
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from joblib import dump

iris = load_iris()
model = LogisticRegression()
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25)
model.fit(x_train, y_train)
dump(model, "iris.joblib")
```

### Initializing the model in eucalyptus
```python
eucalyptus.initialize(api_token='<YOUR_API_KEY>')
features = pd.DataFrame(data=iris.data, columns=iris.feature_names)
target = pd.DataFrame(data=iris.target, columns=['target'])
eucalyptus.create_new_model("iris_clf", "v1", "classifier", features, target)
```

### Log the training data for reference
```python
eucalyptus.log_training_data("iris_clf", "v1", features, target)
```

:::{admonition} Important
:class: Important

We do not store the raw data in our database. Only the data distribution get saved.

:::

### Logging Predictions
```python
feature_names = ['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']
for point in x_test:
    feature = dict(zip(feature_names, point))
    prediction = model.predict([point])
    prediction = int(prediction[0])
    print(feature, prediction)
    eucalyptus.log_prediction(model_name="iris_clf", model_version="v1", features=feature prediction=prediction)
```

### Log ground truth values
```python
request_ids = [
    "9bff624d-9cc8-462c-890f-93c678f2444c",
    "4cf61751-81b4-44d1-8f09-42e762bc65ff",
    "54f7fea3-b9f8-4edd-9b0b-fa0d1bd7bb3b"
]
actuals = [2, 0, 0]
eucalyptus.log_actuals("iris_clf", request_ids=request_ids, actuals=actuals)
```

:::{admonition} Tip
:class: Tip

You can get the request_ids from the dashboard

:::

### Taking it one step further
Machine learning models are often times run as containers with an api endpoint exposed for inference. 
Here is a simple example of running the iris model using a flask service.

```python
from flask import Flask, request
from joblib import load
import eucalyptus
app = Flask(__name__)

model = load("iris.joblib")
eucalyptus.initialize('YOUR_API_KEY')


@app.route("/predict", methods=['POST'])
def predict():
    data = request.json
    feature_names = ['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']
    features = data.get('features')
    prediction = model.predict(features)
    feature_dict = dict(zip(feature_names, features[0]))
    prediction = int(prediction[0])
    eucalyptus.log_prediction(model_name="iris_clf", model_version="v1", features=feature_dict, prediction=prediction)
    return "prediction logged"


if __name__ == "__main__":
    app.run()

```

> **Note**: You can test the predict endpoint using the curl below

```bash
curl -X POST http://127.0.0.1:5000/predict -H 'Content-Type: application/json' -d '{ "features": [[1,2,3,4]] }'
```


